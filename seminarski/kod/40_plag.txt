According to Hannabuss (2001), plagiarism is the “unauthorized use or close imitation of the
ideas and language/expression of someone else and involves representing their work as your
own”. Given the rapid growth of online publishing of text, the act of plagiarism becomes
easier than ever. The problem of plagiarism is particularly evident in journalism (i.e.,
newspapers, blogs) and academia (i.e., student reports, theses) (Clough, 2003). In such cases
significant parts or even entire documents are plagiarized from a single or multiple sources
(i.e., patchwork plagiarism). While many plagiarism cases are easy to be found by human
readers, the great volumes of suspicious and source texts demand automatic plagiarism
detection tools to facilitate this process.
One major issue in plagiarism detection is efficiency (Schleimer, Wilkerson, & Aiken, 2003;
Stein & Meyer zu Eissen, 2006). The suspicious documents should be compared with any
document in the reference collection which may be very large (i.e., the whole indexed Web).
Therefore, similarity estimation between a pair of documents should be based on simple
measures. Additionally, they should be able to capture local similarities where only a likely
short passage is common in both documents. Given that the plagiarized and the original
passages may not be exactly the same in case the plagiarist performed some kind of
paraphrasing, the information used to represent texts should capture the similarity even when
most of the words and word ordering are different (Gustafson, Pera, & Ng, 2008). Existing
approaches in plagiarism detection are based on sequences of words or characters to represent
texts (Schleimer, et al., 2003; Lyon, Malcolm, & Dickerson, 2001; Barrón-Cedeño & Rosso,
2009; Hoad & Zobel, 2003). Since the content information is considered more important, very
frequent words conveying no meaning (i.e., stopwords) are usually excluded (Gustafson, et
al., 2008; Hoad & Zobel, 2003; Chowdhury, Frieder, Grossman, & McCabe, 2002; Potthast,
2Barrón-Cedeño, Eiselt, Stein, & Rosso, 2010) or used to identify the position of important
content terms (Theobald, Siddharth, & Paepcke, 2008).
In this paper, we propose a novel plagiarism detection method that takes full advantage of
stopword occurrences in texts. Instead of following the common practice of eliminating
stopwords, the proposed method eliminates all the other tokens and is entirely based on the
remaining stopword sequences. Therefore, it is a method based exclusively on structural
information rather than content information. We show that stopword n-grams are able to
capture syntactic similarities between suspicious and original documents and they can be used
to detect the plagiarized passage boundaries. Results on a publicly-available corpus
demonstrate that the performance of the proposed approach is competitive when compared
with the best reported results on the same corpus. More importantly, our method achieves
significantly better results when dealing with difficult plagiarism cases where the plagiarized
passages are highly modified and most of the words or phrases have been replaced with
synonyms.
The rest of this paper is organized as follows. The next section describes previous related
work. Section 3 presents the proposed method in detail. The experimental settings and results
are included in Section 4 while the conclusions drawn from this study and suggested future
work directions are given in Section 5.
